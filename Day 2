1. MissingCategoryImputer
If a column is categorical, replace missing values with the most frequent category.

class MissingCategoryImputer(BaseEstimator, TransformerMixin):
    def __init__(self, column, topn = 1):
      self.most_freq  = None
      self.column =  column
      self.topn = topn     

    def fit(self, X, y= None):
        self.most_freq = X[self.column].value_counts().nlargest(self.topn).index[0]
        return self

    def transform(self, X):
        X_new = X.copy()
        X_new[self.column] = X_new[self.column].fillna(self.most_freq)
        return X_new

2. RareCategoryGrouper
class RareCategoryGrouper(BaseEstimator, TransformerMixin):
        def __init__(self, column, threshold = 200):
            self.threshold = threshold
            self.column  = column

        def fit(self, X, y= None):
            value_counts   = X[self.column].value_counts()
            self.rarelist = value_counts[value_counts < self.threshold].index.tolist()
            return self

        def transform(self, X):
            X_new = X.copy()
            X_new[self.column + "grouped"] = X_new[self.column].apply(lambda x: "other" if x in self.rarelist else x)
            return X_new

3. OutlierClipper
import numpy as np
class OutlierClipper(BaseEstimator, TransformerMixin):
    def __init__(self, column):
        self.mean = None
        self.column = column
        self.lower = None
        self.upper = None

    def fit(self, X, y = None):
        self.lower = np.percentile(X[self.column], 0.01)
        self.upper = np.percentile(X[self.column], 0.99)
        return self

    def transform(self, X):
        X_new = X.copy()

        def f1(x):
            if x < self.lower:
               return self.lower
            elif x> self.upper:
               return self.upper
            else:
               return x


        X_new[self.column + "_clipped"] = X_new[self.column].apply(f1)
        return X_new

alternate way 
def transform(self, X):
        X_new = X.copy()
        X_new[self.column + "_clipped"] = X_new[self.column].apply(
            lambda x: 
                self.lower if x < self.lower else 
                self.upper if x > self.upper else 
                x
        )
        return X_new

easiest way

X_new[self.column + "_clipped"] = X_new[self.column].clip(self.lower, self.upper)

4. ZScoreStandardizer
class ZScoreStandardizer(BaseEstimator, transformerMixin):
        def __init__(self, column):
            self.column = column

        def fit(self, X, y = None):
            self.mean = X[self.column].mean()
            self.std = X[self.column].std()
            return self

        def transform(self, X):
            X_new = X.copy()
            X_new[self.column + "_standardized"] = (X_new[self.column] - self.mean)/self.std
            return X_new
            
    Leaarning

You do not need to initialize self.mean = None or self.std = None in __init__() because Python does NOT require "variable declarations" like C, C++, or Java.

In Python:

Attributes can be created anytime, not only inside __init__.

The attribute becomes part of the object the moment you assign it.

üß† The Real Rule You Need to Understand
‚úî You ONLY put in __init__() things that:

are hyperparameters

are given by the user

are not dependent on data

Examples:

column

top_n

threshold

impute_value

These belong in __init__().

‚ùå You should NOT put in __init__() things like:

mean
std
most_frequent_category
lower_limit
upper_limit

5. BooleanFlagFromWords

class BooleanFlagFromWords(BaseEstimator, TransformerMixin):
        def __init__(self, column, keywords = ['free', 'discount']):
            self.column = column
            self.keywords = keywords

        def fit(self, X, y = None):
            return self

        def transform(self, X):
            X_new = X.copy()
            X_new[self.column + "_flagged"] = X_new[self.column].apply(lambda x : 1 if x in self.keywords else 0)
            return X_new
            

            
